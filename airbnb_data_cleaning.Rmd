---
title: "AirBnB Data Cleaning"
author: "Shefali C."
date: "2024-06-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## **Introduction**

The dataset has been taken from [here](https://www.kaggle.com/datasets/arianazmoudeh/airbnbopendata) on Kaggle.  
This notebook contains steps taken to clean this dataset.  


```{r load-library, warning=FALSE, message=FALSE}

#load libraries
library(tidyverse)
library(janitor)
library(tm)
library(knitr)
library(kableExtra)

```
  


```{r set-directories}

#working directory
working_dir <- getwd()
#data directory
data_dir <- paste0(working_dir, "/data/")
#output directory
op_dir <- paste0(working_dir, "/output/")

```

The **`col_character()`** in **`read_csv()`** is used to set the data-type of `license` column to char-type when read by the function.  
- If not used, the column was being read as logical.  
- **`read_csv()`** by default, takes first 1000 rows of dataset and tries detecting the dtype of each column.  
- In the case of `license`, all rows are blank except 2, towards the end which is why this col gets read as logical and a warning is thrown as shown in cell below.  
- The two license values get converted to `NA` in the process.  
- In order to avoid such data loss, it is a good practice to explicitly specify the dtype when such warnings occur.  




```{r read-data}

data2 <- readr::read_csv(paste0(data_dir, "Airbnb_Open_Data.csv"),
                        col_types = cols(license = col_character()))

```


```{r eval=FALSE}

#check warning message
problems(data)

#1 11116    26 1/0/T/F/TRUE/FALSE (expected); 41662/AL (actal value)
#2 72949    26 1/0/T/F/TRUE/FALSE (expected); 41662/AL (actal value)


```


```{r}
#check dtype of all cols; now license is 'char' and the 2 license values are not lost
glimpse(data2)
```

There are 541 duplicate rows in the dataset.


```{r detect-duplicates}

#check for duplicate rows--541 rows
sum(duplicated(data2))

```

Following code can be used to create a subset of all the duplicate rows.  


```{r duplicates-df}

#create a separate dataframe with only duplicate rows
#see all duplicate rows--contains 1082 rows; 541 unique rows, each with 2 copies
duplicate_rows <- data2[duplicated(data2),]

```

Keep only unique values.  
Two functions `distinct()` of **dplyr** package OR `unique()` of **baseR** can be used for the same.  
- Using `distinct()` does not preserve the original order of rows in the dataframe.  



```{r remove-duplicates}

#remove duplicate rows
data2 <- data2 %>% unique()

```

Following code creates a dataframe with 3 columns:  
  - one contains names of columns in original dataframe,  
  - second column contains total number of NA values in that column,  
  - third column contains percentage of blank rows in each column.

```{r na-count-per-column}

##find missing values in each column
missing_values <- data2 %>% 
                    summarise(across(everything(), ~ sum(is.na(.)))) %>% 
                    pivot_longer(everything(),
                                 names_to = "column_name",
                                 values_to = "total_NA") %>% 
                    #add a column indicating % of NA rows
                    mutate(percent_blank_rows = (total_NA/nrow(data2))*100) %>% 
                    #add a "%" sign after rounding off
                    mutate(percent_blank_rows = round(percent_blank_rows,2))
```

Here are all the columns and total missing values they contain.

```{r display-na-count}

#view the missing count dataframe
knitr::kable(missing_values) %>%
        kable_styling(bootstrap_options = "condensed",
                      #full_width = F,
                      position = "center",
                      font_size = 9)

```

- Remove `license` column.  
- Clean the column names- remove spaces, hyphens, reduce to lowercase etc.  
- **`clean_names()`** of **janitor** package handles all these manipulations.


```{r clean-cols}
#License col can be removed as it has values in only 2 rows out of 102,600.
data2 <- data2 %>% select(-license)

##Clean column names
data2 <- janitor::clean_names(data2)
```

## ***Price columns**


```{r unique-chars-in-price}
##1. column- 'price'; currently in char-type

#check for all characters in it except digits
## prices are either like '$100' or '$1,500'
unique(gsub(pattern = "\\d+", replacement = "", data2$price))

```

```{r remove-chars}

#remove '$' and ',' symbols with ""
data2$price <- str_replace_all(data2$price, pattern = "[$,]",
                               replacement = "")

```

```{r price-to-num}
#convert price to numeric
data2$price <- as.numeric(data2$price)

```

```{r unique-chars-service-fee}

## Column- 'Service Fee'; currently in char

#check for all unique characters-- prices only have '$' symbol
unique(gsub(pattern = "\\d+", replacement = "", data2$service_fee))

```

```{r clean-service-fee}

#replace '$' with ""
data2$service_fee <- gsub(pattern = '\\$', replacement = "",
                          data2$service_fee)
#convert to numeric
data2$service_fee <- as.numeric(data2$service_fee)

```

## **Column- 'Last review'**  

- contains dates but dtype is char.

```{r last-review}

#check the format of digits- dd/dd/dddd--returns false
all(grepl(pattern = "\\d{1,2}/\\d{1,2}/\\d{4}", data2$last_review))

```

```{r}
#find row indices where this pattern is present in last-review column
correct_date_format_row_index <- grepl(pattern = "\\d{1,2}/\\d{1,2}/\\d{4}",
                                        data2$last_review)

```

```{r}
#filter out rows where this pattern isn't present
data_incorrect_dates <- data2[!correct_date_format_row_index,
                              c('id', 'name', 'last_review')]
```

```{r}
##check whether all last_reviews values are NA in data_incorrect_dates-- all are 0
sum(!is.na(data_incorrect_dates$last_review))
```

```{r}
##Now check range of numbers in each component of date.
# If range(first 2 digits in all rows) is 1-12 => first 2 digits indicate month
# If range(middle 2 digtis) is 1-31 => days.

##Check first 2 digits
# range is 1-12
unique(str_extract(data2$last_review, pattern = "^\\d{1,2}(?=/)"))
```

```{r}
#extract middle 2 digits
#range 1-31
summary(unique(as.integer(str_extract(data2$last_review, pattern = "(?<=^\\d{1,2}/)\\d{1,2}"))))

```

```{r}
#So, 'last_review' column is in format- mm/dd/yyyy

#conver this column to date
data2$last_review <- lubridate::mdy(data2$last_review)

```

```{r}
#check range of dates
summary(data2$last_review) ##- max value is "2058" which seems odd
```

```{r}
invalid_year_rows <- data2 %>% 
                      filter(year(last_review) > 2022) %>% 
                      select(id, name, last_review)
```

```{r}
#convert year values greater than 2022 to 2022
data2 <- data2 %>% 
          mutate(last_review = case_when(
            year(last_review) > 2022 ~ `year<-`(last_review, 2022),
            TRUE ~ last_review
          ))
```

```{r}
#make a copy of dataframe so far
data3 <- data2
```

```{r}
#Column- Host-identity-verified (unique values check)
#2 values- "unconfirmed", "verified"
unique(data3$host_identity_verified)

```

```{r}
#find total percentage of verified/unconfirmed
#Proportion of confirmed identity/ unconfirmed identity is almost same at ~50%
data3 %>% group_by(host_identity_verified) %>% 
  summarise(total = n()) %>% 
  mutate(percent_share = round((total/nrow(data3)*100),2))

```

```{r}
#Column- Cancellation policy
#3 categories: strict, moderate, flexible
unique(data3$cancellation_policy)

```

```{r}
#check for proportion for each
#roughly same for all 3, ~33%
data3 %>% group_by(cancellation_policy) %>% 
  summarise(total = n()) %>% 
  mutate(percent_share = round((total/nrow(data3))*100,2))

```

```{r}
#Column- Room type
#4 cats- "Private room", "Entire home/apt", "Shared room", "Hotel room"
unique(data3$room_type)

```

```{r}
#Most listings are either Entire home/apt OR private room
data3 %>% group_by(room_type) %>% 
  summarize(total = n()) %>% 
  mutate(percent_share = round((total/nrow(data3))*100,2))
```

```{r}

```

